evaluator:
  batch_size: 32
  image_size: 224
  img_dir: Dataset/images/
  json_path: Dataset/splits_info.json
  k_values: [1, 5, 10]

model:
  vision_encoder:
    type: endovit
    feature_dim: 768
    model_name: egeozsoy/EndoViT
  text_encoder:
    type: clip
    feature_dim: 768
    model_name: openai/clip-vit-base-patch32
  ckp_path: Pretrained/checkpoints/endovit_clip/best.pt


